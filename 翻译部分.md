## 中译英：
Today, we are thrilled to launch Dify v0.15.0 version, introducing the brand-new **Parent-Child Retrieval** feature. This is an advanced technique within Retrieval-Augmented Generation (RAG) systems, designed to significantly enhance information retrieval and contextual understanding. With this feature, Dify can provide more comprehensive, contextually-aware information for AI generation, markedly improving the quality and accuracy of responses from LLM applications.

#### **The Context-Precision Dilemma**

When using knowledge base retrieval systems, users often face a difficult trade-off: On the one hand, search results can be too fragmented, leaving the LLM without enough context to understand the information. On the other hand, they can be too broad, causing information overload and sacrificing precision. This makes it challenging for the LLM to efficiently locate and utilize the necessary information.

In these scenarios, having the appropriate "chunk size" is critical for an AI application to generate accurate yet comprehensive responses. This is why Dify is introducing the new Parent-Child Retrieval feature. It strikes the ideal balance between precision and context, significantly improving the overall performance and reliability of the entire knowledge retrieval process

#### **How to Use Parent-Child Retrieval**

**1. Data Source**: 
Select a data source and import your documents for knowledge retrieval.

**2. Chunking Settings**:
Choose between the standard chunking or the parent-child chunking strategy. You can then set parameters such as chunk size and preview the results.

If you select **Parent-Child Chunking**, two modes are available:

- **Paragraph Mode:** This mode splits the text into paragraphs based on separators and a maximum chunk length, treating each paragraph as a parent chunk. It is best suited for documents that have clear and relatively distinct paragraphs.

- **Whole Document Mode:** This mode treats the entire document as a single parent chunk. It is ideal for scenarios that require retrieval with the full context of the document.




## 英译中：
#### **最新成果｜**插件化架构向企业版平台的战略延伸

继 SaaS 平台取得成功后，Dify 计划将同样的插件化架构应用于其私有化部署的企业平台。企业可在该平台自由选择本地托管插件运行时或云端AWS Lambda环境。目前已有包括30余家世界500强在内的企业客户，正基于该平台开发生成式AI应用以提升运营效能。插件化架构的部署，将帮助客户显著降低资源与成本消耗。对此Gu明确表示：“我们致力于为自建集群部署的企业客户，提供更高效的插件运行时方案。”

Dify将持续通过AWS Lambda动态扩展插件生态，赋能用户构建更多元的应用场景。据其官方路线图 ([Road map](https://dify.ai/blog))公布，平台即将集成模型上下文协议（Model Context Protocol），使大语言模型（LLM) 应用具备与外部工具、数据库及API的交互能力。下一阶段重大升级将包含：增强型检索增强生成（RAG）系统、企业级ETL（提取/转换/加载）数据管道，全面提升企业AI工程化能力。

[Dify 企业版](https://aws.amazon.com/marketplace/pp/prodview-vhluia2quhiuu?sr=0-2&ref_=beagle&applicationId=AWSMPContessa)现已上架 [AWS Marketplace](https://aws.amazon.com/marketplace)，该平台可以帮助用户发现、部署和管理在 AWS 上运行的软件。Dify 在技术和业务两方面都持续受益于 AWS 的专业支持。Gu还表示：“AWS 的指导堪称我们（Dify) 最深入、最富成效的合作，为优化SaaS 部署、平台推广营销，以及企业版用户适配三方面提供了极大的帮助。” Dify将持续借力AWS，通过技术研讨会、专项活动及多元市场推广渠道，将解决方案拓展至更广阔的商业版图。